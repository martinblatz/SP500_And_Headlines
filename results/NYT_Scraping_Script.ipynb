{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Use the pynytimes library to retrieve New York Times new headlines for the WPI Machine Learning course final project.\n",
        "\n",
        "Links to referenced package and API:\n",
        "* https://pypi.org/project/pynytimes/\n",
        "* https://developer.nytimes.com/apis\n"
      ],
      "metadata": {
        "id": "adCS7lZHlmRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pynytimes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlfkQi-TvsOu",
        "outputId": "88fe8cd7-0dd4-4d05-8915-aa031e420b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pynytimes\n",
            "  Downloading pynytimes-0.8.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from pynytimes) (2.25.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from pynytimes) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.10.0->pynytimes) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.10.0->pynytimes) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.10.0->pynytimes) (2.10)\n",
            "Installing collected packages: pynytimes\n",
            "Successfully installed pynytimes-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb5SgwgXsKCe"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from pynytimes import NYTAPI\n",
        "import datetime\n",
        "from datetime import timedelta\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of desired query results\n",
        "NUM_RESULTS = 30"
      ],
      "metadata": {
        "id": "cWm6WF6T-yVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses the max number of query results to build out the column names for\n",
        "# our dataframe of headlines\n",
        "\n",
        "column_names = {0: 'Date'}\n",
        "\n",
        "for i in range(NUM_RESULTS):\n",
        "  column_names[i+1] = f'{\"News \"}{i}'\n",
        "\n",
        "print(column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shxU43u3CmW8",
        "outputId": "20a8d225-df34-4028-ffcd-b638a05829ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Date', 1: 'News 0', 2: 'News 1', 3: 'News 2', 4: 'News 3', 5: 'News 4', 6: 'News 5', 7: 'News 6', 8: 'News 7', 9: 'News 8', 10: 'News 9', 11: 'News 10', 12: 'News 11', 13: 'News 12', 14: 'News 13', 15: 'News 14', 16: 'News 15', 17: 'News 16', 18: 'News 17', 19: 'News 18', 20: 'News 19', 21: 'News 20', 22: 'News 21', 23: 'News 22', 24: 'News 23', 25: 'News 24', 26: 'News 25', 27: 'News 26', 28: 'News 27', 29: 'News 28', 30: 'News 29'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sign up for an API key at https://developer.nytimes.com/apis"
      ],
      "metadata": {
        "id": "0_wbrY_1h_0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "apikey = \"YOUR KEY HERE\"\n",
        "\n",
        "nyt = NYTAPI(apikey, parse_dates=True)"
      ],
      "metadata": {
        "id": "ftjMR7KKv4cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the news desk values used to filter the articles to\n",
        "# data more relevant to the equities markets\n",
        "news_desk = [\n",
        "    \"Business Day\",\n",
        "    \"Business\",\n",
        "    \"Financial\",\n",
        "    \"National\",\n",
        "    \"Personal Investing\",\n",
        "    \"Politics\",\n",
        "    \"U.S.\",\n",
        "    \"World\"\n",
        "]"
      ],
      "metadata": {
        "id": "vZP-Rfp2KSsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Section name is another filter available to the API, but it\n",
        "# appears to work intermittently. I used news desk instead.\n",
        "section_name = [\n",
        "    \"U.S.\",\n",
        "    \"World\"               \n",
        "]"
      ],
      "metadata": {
        "id": "p4NQksAbL5YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function takes in the results of a NYT query and a date variable.\n",
        "# it extracts only the article headlines and creates a list of strings\n",
        "# which starts with the date and then includes all of the headlines.\n",
        "def extract_headlines(articles, date):\n",
        "  headlines = [date]\n",
        "\n",
        "  for article in articles:\n",
        "    headlines.append(article[\"headline\"][\"main\"])\n",
        "\n",
        "  return(headlines)\n"
      ],
      "metadata": {
        "id": "ItJDtdaqcqIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a single search which I have commented out so it isn't run during a \n",
        "# \"run all\". I've retained it for reference \n",
        "\n",
        "# articles = nyt.article_search(\n",
        "#     # query = \"\",\n",
        "#     results = 30,\n",
        "#     dates = {\n",
        "#         \"begin\": datetime.datetime(2018, 1, 31),\n",
        "#         \"end\": datetime.datetime(2022, 3, 31)\n",
        "#     },\n",
        "#     options = {\n",
        "#         # \"sort\": \"oldest\",\n",
        "#         \"sources\": [\n",
        "#             \"New York Times\",\n",
        "#             \"AP\",\n",
        "#             \"Reuters\"\n",
        "#         ],\n",
        "#         \"section_name\": section_name\n",
        "#         # \"news_desk\": news_desk\n",
        "#         # \"type_of_material\": types_of_material\n",
        "#     }\n",
        "# )\n",
        "# len(articles)"
      ],
      "metadata": {
        "id": "eCUEnDNBHeqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intended to run overnight\n"
      ],
      "metadata": {
        "id": "MRiMMc_0MFHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the data list\n",
        "archive_news = []\n",
        "\n",
        "# set a start date and end date for the query\n",
        "start_date = datetime.datetime(2018, 1, 1)\n",
        "end_date = datetime.datetime(2018, 1, 3)\n",
        "\n",
        "# create a timedelta object to increment the loop 1 day at a time\n",
        "delta = timedelta(days=1)\n",
        "\n",
        "# set progress to 0 and calculate the total number of requests. \n",
        "# Used for convenience to let us know long the query still has to run\n",
        "progress = 0\n",
        "tot_days = (end_date - start_date).days\n",
        "\n",
        "while start_date <= end_date:\n",
        "  # print status of these requests\n",
        "  print(start_date.strftime(\"%Y-%m-%d\"), progress/tot_days*100, \"%\")\n",
        "  progress += 1\n",
        "  \n",
        "  # insert a 6 second delay to stay under the API Max requests (10/minute) \n",
        "  time.sleep(6) \n",
        "\n",
        "  # Build and execute the query\n",
        "  articles = nyt.article_search(\n",
        "    # query = \"\",\n",
        "    results = NUM_RESULTS,\n",
        "    dates = {\n",
        "        \"begin\": start_date,\n",
        "        \"end\": start_date\n",
        "    },\n",
        "    options = {\n",
        "        # \"sort\": \"oldest\",\n",
        "        \"sources\": [\n",
        "            \"New York Times\",\n",
        "            \"AP\",\n",
        "            \"Reuters\"\n",
        "        ],\n",
        "        # \"section_name\": section_name,\n",
        "        \"news_desk\": news_desk\n",
        "        # \"type_of_material\": types_of_material\n",
        "    }\n",
        "    )\n",
        "  \n",
        "  # append the results from this iteration before starting the next\n",
        "  archive_news.append(extract_headlines(articles, start_date))\n",
        "  start_date += delta\n",
        "\n",
        "# convert the list to a pandas dataframe\n",
        "# use the column names we created earlier to improve readability\n",
        "df = pd.DataFrame(archive_news)\n",
        "df=df.rename(columns=column_names)\n",
        "\n",
        "# Use Google Colab capabilities to save the dataframe to the VM and download it\n",
        "from google.colab import files\n",
        "filename = \"NYTNews test.csv\"\n",
        "\n",
        "df.to_csv(filename, encoding = 'utf-8-sig', index=False) \n",
        "files.download(filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "GOfT_5tsMC0I",
        "outputId": "a7e593eb-4c9f-4a73-930e-9b293092f7c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2018-01-01 0.0 %\n",
            "2018-01-02 50.0 %\n",
            "2018-01-03 100.0 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_35556fe1-221d-4a2d-bcd9-08af06e20d35\", \"NYTNews test.csv\", 3895)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# infiles = [\"NYTNews 1H2020.csv\", \n",
        "#          \"NYTNews 1H2020.csv\",\n",
        "#          \"NYTNews 1H2020.csv\",\n",
        "#          \"NYTNews 1H2020.csv\",\n",
        "#          \"NYTNews 1H2020.csv\",\n",
        "#          \"NYTNews 1H2020.csv\",  \n",
        "#          ]\n",
        "\n",
        "# outfile = \"NYTNews.csv\"\n",
        "\n",
        "# df = pd.DataFrame()\n",
        "\n",
        "# for file in infiles:\n",
        "#   # tempDf = pd.read_csv(file, index_col='Date')\n",
        "#   tempDf = pd.read_csv(file)\n",
        "\n",
        "#   frames = [df, tempDf]\n",
        "#   df = pd.concat(frames)\n",
        "#   print(len(df))\n",
        "\n",
        "\n",
        "# df.to_csv(outfile, encoding = 'utf-8-sig', index=False) \n",
        "# files.download(outfile)"
      ],
      "metadata": {
        "id": "M59CwTmtynjg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}